arguments: src/process_dataset.py
--------------------
tensorflow version: 1.7.0
--------------------
git hash: b'096ed770f163957c1e56efa7feeb194773920f6e'
--------------------
b'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\nindex 7d5e735..240b6c0 100644\n--- a/src/align/align_dataset_mtcnn.py\n+++ b/src/align/align_dataset_mtcnn.py\n@@ -1,18 +1,18 @@\n """Performs face alignment and stores face thumbnails in the output directory."""\n # MIT License\n-# \n+#\n # Copyright (c) 2016 David Sandberg\n-# \n+#\n # Permission is hereby granted, free of charge, to any person obtaining a copy\n # of this software and associated documentation files (the "Software"), to deal\n # in the Software without restriction, including without limitation the rights\n # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n # copies of the Software, and to permit persons to whom the Software is\n # furnished to do so, subject to the following conditions:\n-# \n+#\n # The above copyright notice and this permission notice shall be included in all\n # copies or substantial portions of the Software.\n-# \n+#\n # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n@@ -45,15 +45,15 @@ def main(args):\n     src_path,_ = os.path.split(os.path.realpath(__file__))\n     facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n     dataset = facenet.get_dataset(args.input_dir)\n-    \n+\n     print(\'Creating networks and loading parameters\')\n-    \n+\n     with tf.Graph().as_default():\n         gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n         sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n         with sess.as_default():\n             pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n+\n     minsize = 20 # minimum size of face\n     threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n     factor = 0.709 # scale factor\n@@ -61,7 +61,7 @@ def main(args):\n     # Add a random key to the filename to allow alignment using multiple processes\n     random_key = np.random.randint(0, high=99999)\n     bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n+\n     with open(bounding_boxes_filename, "w") as text_file:\n         nrof_images_total = 0\n         nrof_successfully_aligned = 0\n@@ -92,7 +92,7 @@ def main(args):\n                         if img.ndim == 2:\n                             img = facenet.to_rgb(img)\n                         img = img[:,:,0:3]\n-    \n+\n                         bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n                         nrof_faces = bounding_boxes.shape[0]\n                         if nrof_faces>0:\n@@ -133,21 +133,21 @@ def main(args):\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n-                            \n+\n     print(\'Total number of images: %d\' % nrof_images_total)\n     print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n+\n \n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n-    \n+\n     parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n     parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n     parser.add_argument(\'--image_size\', type=int,\n         help=\'Image size (height, width) in pixels.\', default=182)\n     parser.add_argument(\'--margin\', type=int,\n         help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n+    parser.add_argument(\'--random_order\',\n         help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n         help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\ndiff --git a/src/classifier.py b/src/classifier.py\nindex 749db4d..e46010d 100644\n--- a/src/classifier.py\n+++ b/src/classifier.py\n@@ -1,19 +1,19 @@\n """An example of how to use your own dataset to train a classifier that recognizes people.\n """\n # MIT License\n-# \n+#\n # Copyright (c) 2016 David Sandberg\n-# \n+#\n # Permission is hereby granted, free of charge, to any person obtaining a copy\n # of this software and associated documentation files (the "Software"), to deal\n # in the Software without restriction, including without limitation the rights\n # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n # copies of the Software, and to permit persons to whom the Software is\n # furnished to do so, subject to the following conditions:\n-# \n+#\n # The above copyright notice and this permission notice shall be included in all\n # copies or substantial portions of the Software.\n-# \n+#\n # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n@@ -37,13 +37,13 @@ import pickle\n from sklearn.svm import SVC\n \n def main(args):\n-  \n+\n     with tf.Graph().as_default():\n-      \n+\n         with tf.Session() as sess:\n-            \n+\n             np.random.seed(seed=args.seed)\n-            \n+\n             if args.use_split_dataset:\n                 dataset_tmp = facenet.get_dataset(args.data_dir)\n                 train_set, test_set = split_dataset(dataset_tmp, args.min_nrof_images_per_class, args.nrof_train_images_per_class)\n@@ -56,24 +56,24 @@ def main(args):\n \n             # Check that there are at least one training image per class\n             for cls in dataset:\n-                assert(len(cls.image_paths)>0, \'There must be at least one image for each class in the dataset\')            \n+                assert(len(cls.image_paths)>0, \'There must be at least one image for each class in the dataset\')\n+\n \n-                 \n             paths, labels = facenet.get_image_paths_and_labels(dataset)\n-            \n+\n             print(\'Number of classes: %d\' % len(dataset))\n             print(\'Number of images: %d\' % len(paths))\n-            \n+\n             # Load the model\n             print(\'Loading feature extraction model\')\n             facenet.load_model(args.model)\n-            \n+\n             # Get input and output tensors\n             images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n             embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n             phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n             embedding_size = embeddings.get_shape()[1]\n-            \n+\n             # Run forward pass to calculate embeddings\n             print(\'Calculating features for images\')\n             nrof_images = len(paths)\n@@ -86,7 +86,7 @@ def main(args):\n                 images = facenet.load_data(paths_batch, False, False, args.image_size)\n                 feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n                 emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n-            \n+\n             classifier_filename_exp = os.path.expanduser(args.classifier_filename)\n \n             if (args.mode==\'TRAIN\'):\n@@ -94,7 +94,7 @@ def main(args):\n                 print(\'Training classifier\')\n                 model = SVC(kernel=\'linear\', probability=True)\n                 model.fit(emb_array, labels)\n-            \n+\n                 # Create a list of class names\n                 class_names = [ cls.name.replace(\'_\', \' \') for cls in dataset]\n \n@@ -102,7 +102,7 @@ def main(args):\n                 with open(classifier_filename_exp, \'wb\') as outfile:\n                     pickle.dump((model, class_names), outfile)\n                 print(\'Saved classifier model to file "%s"\' % classifier_filename_exp)\n-                \n+\n             elif (args.mode==\'CLASSIFY\'):\n                 # Classify images\n                 print(\'Testing classifier\')\n@@ -114,14 +114,14 @@ def main(args):\n                 predictions = model.predict_proba(emb_array)\n                 best_class_indices = np.argmax(predictions, axis=1)\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-                \n+\n                 for i in range(len(best_class_indices)):\n                     print(\'%4d  %s: %.3f\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n-                    \n+\n                 accuracy = np.mean(np.equal(best_class_indices, labels))\n                 print(\'Accuracy: %.3f\' % accuracy)\n-                \n-            \n+\n+\n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\n     train_set = []\n     test_set = []\n@@ -134,22 +134,22 @@ def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_clas\n             test_set.append(facenet.ImageClass(cls.name, paths[nrof_train_images_per_class:]))\n     return train_set, test_set\n \n-            \n+\n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n-    \n+\n     parser.add_argument(\'mode\', type=str, choices=[\'TRAIN\', \'CLASSIFY\'],\n-        help=\'Indicates if a new classifier should be trained or a classification \' + \n+        help=\'Indicates if a new classifier should be trained or a classification \' +\n         \'model should be used for classification\', default=\'CLASSIFY\')\n     parser.add_argument(\'data_dir\', type=str,\n         help=\'Path to the data directory containing aligned LFW face patches.\')\n-    parser.add_argument(\'model\', type=str, \n+    parser.add_argument(\'model\', type=str,\n         help=\'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file\')\n-    parser.add_argument(\'classifier_filename\', \n-        help=\'Classifier model file name as a pickle (.pkl) file. \' + \n+    parser.add_argument(\'classifier_filename\',\n+        help=\'Classifier model file name as a pickle (.pkl) file. \' +\n         \'For training this is the output and for classification this is an input.\')\n-    parser.add_argument(\'--use_split_dataset\', \n-        help=\'Indicates that the dataset specified by data_dir should be split into a training and test set. \' +  \n+    parser.add_argument(\'--use_split_dataset\',\n+        help=\'Indicates that the dataset specified by data_dir should be split into a training and test set. \' +\n         \'Otherwise a separate test set can be specified using the test_data_dir option.\', action=\'store_true\')\n     parser.add_argument(\'--test_data_dir\', type=str,\n         help=\'Path to the test data directory containing aligned images used for testing.\')\n@@ -163,7 +163,7 @@ def parse_arguments(argv):\n         help=\'Only include classes with at least this number of images in the dataset\', default=20)\n     parser.add_argument(\'--nrof_train_images_per_class\', type=int,\n         help=\'Use this number of images from each class for training and the rest for testing\', default=10)\n-    \n+\n     return parser.parse_args(argv)\n \n if __name__ == \'__main__\':'